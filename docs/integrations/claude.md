# Claude Integration

Use Prosody Protocol with Anthropic's Claude to build emotion-aware AI assistants.

## Concept

IML provides structured prosodic context that Claude can use to understand
*how* something was said, not just *what* was said. This enables Claude to
distinguish sarcasm from sincerity, urgency from calm, and frustration from
neutral statements.

## Setup

```bash
pip install prosody-protocol anthropic
```

## Sending IML to Claude

```python
import anthropic
from prosody_protocol import IMLParser

client = anthropic.Anthropic()

# User speaks with sarcasm (IML generated by AudioToIML)
iml_input = '''<utterance emotion="sarcastic" confidence="0.89">
  Oh that's <prosody pitch_contour="fall-rise">wonderful</prosody>.
</utterance>'''

message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    system="""You receive text with IML prosody markup. The markup tells you
    HOW words were spoken, revealing emotional intent. The `emotion` attribute
    and prosodic features (pitch, volume, contour) indicate the speaker's
    actual feelings. Respond appropriately to the emotional intent, not just
    the literal words.""",
    messages=[{"role": "user", "content": iml_input}],
)

print(message.content[0].text)
# "I can tell you're being sarcastic. What's actually bothering you?"
```

## Parsing IML Before Sending

Extract structured data for richer prompts:

```python
from prosody_protocol import IMLParser

parser = IMLParser()
doc = parser.parse(iml_input)

utt = doc.utterances[0]
context = f"[Speaker emotion: {utt.emotion}, confidence: {utt.confidence}]"
plain_text = parser.to_plain_text(doc)

# Send structured context to Claude
message = client.messages.create(
    model="claude-sonnet-4-5-20250929",
    system="You are an empathetic assistant. Use the emotional context provided.",
    messages=[{
        "role": "user",
        "content": f"{context}\n{plain_text}",
    }],
)
```

## Constitutional AI: Intent Verification

Use prosodic analysis to verify user intent before executing high-risk actions:

```python
from prosody_protocol import AudioToIML, IMLParser

converter = AudioToIML()
parser = IMLParser()

def verify_intent(audio_path: str, action: str) -> bool:
    """Require calm, deliberate prosody for destructive actions."""
    iml = converter.convert(audio_path)
    doc = parser.parse(iml)

    for utt in doc.utterances:
        if utt.emotion in ("sarcastic", "angry", "frustrated"):
            print(f"Blocked: speaker appears {utt.emotion}")
            return False
        if utt.confidence and utt.confidence < 0.7:
            print("Blocked: low confidence in emotion detection")
            return False

    return True

# Example: verify before deleting files
if verify_intent("user_command.wav", "delete all temp files"):
    execute_action()
else:
    ask_for_confirmation()
```

## Full Pipeline Example

```python
from prosody_protocol import AudioToIML, IMLParser, IMLValidator

converter = AudioToIML()
parser = IMLParser()
validator = IMLValidator()

# 1. Convert audio to IML
iml = converter.convert("user_message.wav")

# 2. Validate
result = validator.validate(iml)
assert result.valid, f"Invalid IML: {result.issues}"

# 3. Parse for structured access
doc = parser.parse(iml)
emotion = doc.utterances[0].emotion
text = parser.to_plain_text(doc)

# 4. Send to Claude with full context
print(f"User said: {text}")
print(f"Detected emotion: {emotion}")
```
